
# import asyncio
# import math
# import cv2
# import numpy as np
# import rclpy
# from rclpy.node import Node
# from sensor_msgs.msg import Image
# from cv_bridge import CvBridge

# from mavsdk import System
# from mavsdk.mission import MissionItem, MissionPlan
# from mavsdk.action import OrbitYawBehavior

# # ---------------- CONFIG ----------------
# VIDEO_PATH = "vid.webm"        
# AREA_THRESHOLD = 3000          
# SPIRAL_RADII = range(5, 20, 5)
# CAMERA_TOPIC = '/world/default/model/x500_gimbal_0/link/camera_link/sensor/camera/image'
# # ----------------------------------------

# object_detected = False
# cv_enabled = False  
# markers = []      

# # -------- SIMPLE CV --------
# def simple_cv_detect(frame):
#     hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
#     lower_red = np.array([0, 120, 70])
#     upper_red = np.array([10, 255, 255])
#     mask = cv2.inRange(hsv, lower_red, upper_red)
#     area = cv2.countNonZero(mask)
#     return area > AREA_THRESHOLD


# async def cv_demo_monitor(drone: System):
#     global object_detected, cv_enabled

#     cap = cv2.VideoCapture(VIDEO_PATH)
#     if not cap.isOpened():
#         print("âŒ Demo video not found")
#         return

#     print("ğŸ‘€ CV demo ready (waiting for search)")

#     while True:
#         if not cv_enabled:
#             await asyncio.sleep(0.2)
#             continue

#         ret, frame = cap.read()
#         if not ret:
#             break

#         if simple_cv_detect(frame):
#             print("ğŸ¯ Object detected (Simple CV)")
#             object_detected = True
#             await save_detection_gps(drone)
#             break

#         await asyncio.sleep(0.05)


# # -------- DRONE HELPERS --------
# async def landed(drone):
#     async for state in drone.telemetry.landed_state():
#         if state == state.ON_GROUND:
#             print("ğŸ›¬ Drone landed")
#             break


# async def wait_one_orbit(drone: System, center_lat: float, center_lon: float, radius_m: float,
#                          circle_tolerance_m: float = 1.0,
#                          start_tolerance_deg: float = 10 * 1e-6):
#     """
#     ØªÙ†ØªØ¸Ø± Ø§Ù„Ø¯Ø±ÙˆÙ† Ù„Ø¥ÙƒÙ…Ø§Ù„ Ø¯ÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø© Ø­ÙˆÙ„ Ù…Ø±ÙƒØ² Ù…Ø¹ÙŠÙ†
#     """
#     def distance_m(lat1, lon1, lat2, lon2):
#         R = 6371000
#         phi1 = math.radians(lat1)
#         phi2 = math.radians(lat2)
#         dphi = math.radians(lat2 - lat1)
#         dlambda = math.radians(lon2 - lon1)
#         a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2
#         c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
#         return R * c

#     # Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø¯ÙˆØ±Ø©
#     print("Waiting for drone to reach orbit circle...")
#     async for position in drone.telemetry.position():
#         d = distance_m(center_lat, center_lon, position.latitude_deg, position.longitude_deg)
#         if abs(d - radius_m) <= circle_tolerance_m:
#             start_lat = position.latitude_deg
#             start_lon = position.longitude_deg
#             print(f"Orbit started near: {start_lat}, {start_lon}")
#             break

#     # Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø­ØªÙ‰ ÙŠØºØ§Ø¯Ø± Ø§Ù„Ù†Ù‚Ø·Ø©
#     async for position in drone.telemetry.position():
#         if (abs(position.latitude_deg - start_lat) > start_tolerance_deg or
#             abs(position.longitude_deg - start_lon) > start_tolerance_deg):
#             print("Left start point, orbit in progress...")
#             break

#     # Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø­ØªÙ‰ Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„Ù†Ù‚Ø·Ø© Ù†ÙØ³Ù‡Ø§ (Ø¯ÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø©)
#     print("Waiting for drone to come back to start of orbit (one full round)...")
#     async for position in drone.telemetry.position():
#         if (abs(position.latitude_deg - start_lat) <= start_tolerance_deg and
#             abs(position.longitude_deg - start_lon) <= start_tolerance_deg):
#             print("One full orbit completed!")
#             break


# async def save_detection_gps(drone):
#     pos = await anext(drone.telemetry.position())
#     lat = pos.latitude_deg
#     lon = pos.longitude_deg
#     alt = pos.absolute_altitude_m
#     print(f"ğŸ“ GPS SAVED â†’ LAT:{lat}, LON:{lon}, ALT:{alt}")
#     markers.append((lat, lon, alt))
#     await add_marker_to_mission(drone, lat, lon, alt)


# async def add_marker_to_mission(drone, lat, lon, alt):
#     """
#     Ø¥Ø¶Ø§ÙØ© Marker Ù…Ø³ØªÙ‚Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø±ÙŠØ·Ø© (ÙŠÙ…ÙƒÙ† ØªØ¹Ø¯ÙŠÙ„Ù‡ Ø­Ø³Ø¨ GCS)
#     """
#     # Ù‡Ù†Ø§ Marker Ù…Ø³ØªÙ‚Ù„ØŒ Ø¨Ø¹Ø¶ Ø§Ù„Ù€ GCS Ù‚Ø¯ ØªØ­ØªØ§Ø¬ API Ø®Ø§Øµ Ù„Ø¥Ø¶Ø§ÙØªÙ‡ ÙØ¹Ù„ÙŠÙ‹Ø§
#     print(f"ğŸ“Œ Marker added at LAT:{lat}, LON:{lon}, ALT:{alt}")


# # -------- SPIRAL SEARCH --------
# async def spiral_search(drone, lat, lon, alt):
#     global object_detected, cv_enabled

#     print("ğŸ” Spiral search started")

#     for radius in SPIRAL_RADII:
#         print(f"ğŸ”„ Starting orbit radius {radius} m")
#         await drone.action.do_orbit(
#             radius_m=radius,
#             velocity_ms=2.0,
#             yaw_behavior=OrbitYawBehavior.HOLD_FRONT_TO_CIRCLE_CENTER,
#             latitude_deg=lat,
#             longitude_deg=lon,
#             absolute_altitude_m=alt
#         )

#         await wait_one_orbit(drone, lat, lon, radius)
#         cv_enabled = True 

#         if object_detected:
#             print("ğŸ›‘ Search stopped (CV triggered)")
#             break

#     print("âœ… Spiral search completed")


# # -------- MAIN --------
# async def main():
#     global object_detected

#     drone = System()
#     print("ğŸ”Œ Connecting...")
#     await drone.connect(system_address="udp://:14540")

#     async for state in drone.core.connection_state():
#         if state.is_connected:
#             print("âœ… Drone connected")
#             break

#     print("ğŸ”“ Arming")
#     await drone.action.arm()
#     await asyncio.sleep(2)

#     print("ğŸš€ Takeoff")
#     await drone.action.takeoff()
#     await asyncio.sleep(5)

#     home = await anext(drone.telemetry.home())
#     home_lat = home.latitude_deg
#     home_lon = home.longitude_deg
#     home_alt = home.absolute_altitude_m + 2

#     cv_task = asyncio.create_task(cv_demo_monitor(drone))

# # 0.000135 Ù‡ÙŠ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„ØªÙŠ ØªØ­ÙˆÙ„ Ø§Ù„Ù€ 15 Ù…ØªØ± Ø¥Ù„Ù‰ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø¬ØºØ±Ø§ÙÙŠØ©
#     target_lat = home_lat + (11.11 * 0.000009)  # Y = 11.11
#     target_lon = home_lon + (15.00 * 0.000009)  # X = 15.00

#     mission = MissionPlan([
#         MissionItem(
#             target_lat, target_lon, 2,
#             3, True,
#             float("nan"), float("nan"),
#             MissionItem.CameraAction.NONE,
#             float("nan"), float("nan"),
#             1, 8, float("nan"),
#             MissionItem.VehicleAction.NONE
#         )
#     ])

#     print("ğŸ“¤ Uploading mission")
#     await drone.mission.upload_mission(mission)

#     print("â–¶ï¸ Starting mission")
#     await drone.mission.start_mission()

#     async for progress in drone.mission.mission_progress():
#         print(f"Mission: {progress.current}/{progress.total}")
#         if progress.current == progress.total:
#             print("ğŸ Mission done")
#             break

#     await drone.mission.pause_mission()

#     # Spiral search
#     await spiral_search(drone, target_lat, target_lon, home_alt)

#     # RTL if detected
#     if object_detected:
#         print("ğŸ  RTL (CV Triggered)")
#         await drone.action.return_to_launch()

#     await landed(drone)
#     cv_task.cancel()

#     print("âœ… Demo finished")


# asyncio.run(main())





# ////////////////////////////////////////////////////////////////////////////////




# import asyncio
# import math
# import cv2
# import numpy as np
# import rclpy
# from rclpy.node import Node
# from sensor_msgs.msg import Image
# from cv_bridge import CvBridge
# from ultralytics import YOLO

# from mavsdk import System
# from mavsdk.mission import MissionItem, MissionPlan
# from mavsdk.action import OrbitYawBehavior

# # ---------------- CONFIG ----------------
# # Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø®Ø§Øµ Ø¨ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ø¯Ø±ÙˆÙ† ÙÙŠ Gazebo
# CAMERA_TOPIC = '/world/default/model/x500_gimbal_0/link/camera_link/sensor/camera/image'
# SPIRAL_RADII = [5, 10, 15, 20]
# # ----------------------------------------

# object_detected = False
# cv_enabled = False  
# model = YOLO('yolov8n.pt') # ØªØ­Ù…ÙŠÙ„ Ù…ÙˆØ¯ÙŠÙ„ YOLO

# # -------- ROS 2 AI NODE --------
# class DroneVisionNode(Node):
#     def __init__(self, drone):
#         super().__init__('drone_vision_node')
#         self.drone = drone
#         self.bridge = CvBridge()
#         self.subscription = self.create_subscription(
#             Image,
#             CAMERA_TOPIC,
#             self.image_callback,
#             10)
#         print("ğŸš€ YOLO AI Node is ready and listening...")

#     def image_callback(self, msg):
#         global object_detected, cv_enabled
        
#         # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„Ø¨Ø« Ø§Ù„Ø­ÙŠ Ø¯Ø§Ø¦Ù…Ø§Ù‹
#         frame = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
#         annotated_frame = frame.copy()

#         # Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø´Ø®Øµ ÙÙ‚Ø· Ø¥Ø°Ø§ Ø¨Ø¯Ø£ Ø§Ù„Ø¨Ø­Ø« ÙˆÙ„Ù… Ù†ÙƒØªØ´Ù Ø£Ø­Ø¯Ø§Ù‹ Ø¨Ø¹Ø¯
#         if cv_enabled and not object_detected:
#             # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø®ÙÙØ© imgsz=320 Ù„Ù…Ù†Ø¹ Ù…Ø´ÙƒÙ„Ø© "Killed"
#             results = model(frame, stream=True, conf=0.4, verbose=False, imgsz=320)
            
#             for r in results:
#                 annotated_frame = r.plot() 
#                 for box in r.boxes:
#                     if int(box.cls[0]) == 0: # 0 Ù‡Ùˆ ÙƒÙˆØ¯ Ø§Ù„Ø¥Ù†Ø³Ø§Ù†
#                         print("ğŸ¯ TARGET DETECTED BY YOLO!")
#                         object_detected = True
#                         cv2.imwrite("detected_person.jpg", annotated_frame)
#                         asyncio.run_coroutine_threadsafe(save_detection_gps(self.drone), loop)

#         # Ø¹Ø±Ø¶ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù„Ù„Ø¬Ù†Ø© (Ù„Ù† ÙŠØªÙˆÙ‚Ù Ø§Ù„Ø¨Ø«)
#         cv2.imshow("Rescue Live Stream", annotated_frame)
#         cv2.waitKey(1)

# # -------- DRONE HELPERS (The functions you wanted to keep) --------

# async def wait_one_orbit(drone: System, center_lat: float, center_lon: float, radius_m: float,
#                          circle_tolerance_m: float = 1.5,
#                          start_tolerance_deg: float = 12 * 1e-6):
#     """
#     ØªÙ†ØªØ¸Ø± Ø§Ù„Ø¯Ø±ÙˆÙ† Ù„Ø¥ÙƒÙ…Ø§Ù„ Ø¯ÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø© (360 Ø¯Ø±Ø¬Ø©) Ø­ÙˆÙ„ Ø§Ù„Ù‡Ø¯Ù
#     """
#     def distance_m(lat1, lon1, lat2, lon2):
#         R = 6371000
#         phi1, phi2 = math.radians(lat1), math.radians(lat2)
#         dphi = math.radians(lat2 - lat1)
#         dlambda = math.radians(lon2 - lon1)
#         a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2
#         return R * 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))

#     print(f"Waiting for drone to complete orbit at {radius_m}m...")
    
#     # 1. Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù…Ø­ÙŠØ· Ø§Ù„Ø¯Ø§Ø¦Ø±Ø©
#     start_lat, start_lon = 0, 0
#     async for pos in drone.telemetry.position():
#         if abs(distance_m(center_lat, center_lon, pos.latitude_deg, pos.longitude_deg) - radius_m) <= circle_tolerance_m:
#             start_lat, start_lon = pos.latitude_deg, pos.longitude_deg
#             print(f"Orbit started at point: {start_lat}, {start_lon}")
#             break

#     # 2. Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ø§Ø¨ØªØ¹Ø§Ø¯ Ø¹Ù† Ù†Ù‚Ø·Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
#     async for pos in drone.telemetry.position():
#         if object_detected: return # Ø§Ù„Ø®Ø±ÙˆØ¬ Ø¥Ø°Ø§ ÙˆØ¬Ø¯Ù†Ø§ Ø§Ù„Ø´Ø®Øµ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¯ÙˆØ±Ø§Ù†
#         if abs(pos.latitude_deg - start_lat) > start_tolerance_deg or abs(pos.longitude_deg - start_lon) > start_tolerance_deg:
#             break

#     # 3. Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ù†ÙØ³ Ø§Ù„Ù†Ù‚Ø·Ø© (Ø¯ÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø©)
#     async for pos in drone.telemetry.position():
#         if object_detected: return
#         if abs(pos.latitude_deg - start_lat) <= start_tolerance_deg and abs(pos.longitude_deg - start_lon) <= start_tolerance_deg:
#             print(f"âœ… Full orbit at {radius_m}m completed!")
#             break

# async def save_detection_gps(drone):
#     async for pos in drone.telemetry.position():
#         print(f"ğŸ“ VICTIM CAPTURED â†’ LAT:{pos.latitude_deg}, LON:{pos.longitude_deg}")
#         break

# # -------- SPIRAL SEARCH --------
# async def spiral_search(drone, lat, lon, alt):
#     global cv_enabled, object_detected
#     print("ğŸ” Autonomous Spiral Search Started")
#     cv_enabled = True # ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ ÙˆØ§Ù„Ù€ YOLO

#     for radius in SPIRAL_RADII:
#         if object_detected: break
        
#         print(f"ğŸ”„ Orbiting Radius: {radius}m")
#         await drone.action.do_orbit(
#             radius_m=radius,
#             velocity_ms=1.5,
#             yaw_behavior=OrbitYawBehavior.HOLD_FRONT_TO_CIRCLE_CENTER,
#             latitude_deg=lat,
#             longitude_deg=lon,
#             absolute_altitude_m=alt
#         )

#         # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙŠ Ø·Ù„Ø¨ØªÙ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„ÙŠÙ‡Ø§
#         await wait_one_orbit(drone, lat, lon, radius)

#     print("âœ… Search Phase Finished")

# # -------- MAIN EXECUTION --------
# async def main():
#     global loop
#     loop = asyncio.get_running_loop()
    
#     rclpy.init()
#     drone = System()
#     await drone.connect(system_address="udp://:14540")
    
#     # ØªØ´ØºÙŠÙ„ Ø±Ø¤ÙŠØ© Ø§Ù„ÙƒÙ…Ø¨ÙŠÙˆØªØ± (ROS 2) ÙÙŠ Ø®ÙŠØ· Ù…Ù†ÙØµÙ„
#     vision_node = DroneVisionNode(drone)
#     asyncio.create_task(asyncio.to_thread(rclpy.spin, vision_node))

#     print("ğŸ”“ Arming and Taking off...")
#     await drone.action.arm()
#     await drone.action.takeoff()
#     await asyncio.sleep(8)

#     home = await anext(drone.telemetry.home())
#     target_lat = home.latitude_deg + (11.11 * 0.000009)
#     target_lon = home.longitude_deg + (15.00 * 0.000009)

#     print("âœˆï¸ Proceeding to search area...")
#     await drone.action.goto_location(target_lat, target_lon, home.absolute_altitude_m + 5, 0)
#     await asyncio.sleep(10)

#     # Ø¨Ø¯Ø¡ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­Ù„Ø²ÙˆÙ†ÙŠ Ø§Ù„Ù…Ø·ÙˆØ±
#     await spiral_search(drone, target_lat, target_lon, home.absolute_altitude_m + 5)

#     if object_detected:
#         print("ğŸ  Success! Returning to base.")
#         await drone.action.return_to_launch()
    
#     await asyncio.sleep(15)
#     rclpy.shutdown()

# if __name__ == "__main__":
#     asyncio.run(main())






#///////////////////////////////////////////////////////////////////////////



import asyncio
import math
import cv2
import numpy as np
import rclpy
import requests  
import threading
from rclpy.node import Node
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
from ultralytics import YOLO

from mavsdk import System
from mavsdk.mission import MissionItem, MissionPlan
from mavsdk.action import OrbitYawBehavior

# ---------------- CONFIG ----------------
CAMERA_TOPIC = '/world/default/model/x500_gimbal_0/link/camera_link/sensor/camera/image'
SPIRAL_RADII = [5, 10, 15, 20]

API_URL = "https://v0-sky-guard-drone-dashboard.vercel.app/api/detection"
# ----------------------------------------

object_detected = False
cv_enabled = False  
model = YOLO('yolov8n.pt') 

def upload_to_web(lat, lon, image_path):
    try:
        payload = {"lat": str(lat), "lon": str(lon), "status": "Person Detected"}
        with open(image_path, "rb") as img:
            files = {"image": img}
            response = requests.post(API_URL, data=payload, files=files, timeout=10)
            print(f"ğŸ“¡ Web Update: Success ({response.status_code})")
    except Exception as e:
        print(f"ğŸ“¡ Web Update: Failed ({e})")

# -------- ROS 2 AI NODE --------
class DroneVisionNode(Node):
    def __init__(self, drone):
        super().__init__('drone_vision_node')
        self.drone = drone
        self.bridge = CvBridge()
        self.subscription = self.create_subscription(
            Image,
            CAMERA_TOPIC,
            self.image_callback,
            10)
        print("ğŸš€ YOLO AI Node is ready and listening...")

    def image_callback(self, msg):
        global object_detected, cv_enabled
        
        frame = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
        annotated_frame = frame.copy()

        if cv_enabled and not object_detected:
            results = model(frame, stream=True, conf=0.4, verbose=False, imgsz=320)
            
            for r in results:
                annotated_frame = r.plot() 
                for box in r.boxes:
                    if int(box.cls[0]) == 0: 
                        print("ğŸ¯ TARGET DETECTED!")
                        object_detected = True
                        image_path = "detected_person.jpg"
                        cv2.imwrite(image_path, annotated_frame)
                        
                        asyncio.run_coroutine_threadsafe(self.process_detection(image_path), loop)

        cv2.imshow("Rescue Live Stream", annotated_frame)
        cv2.waitKey(1)

    async def process_detection(self, image_path):
        # 1. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ù…Ù† Ø§Ù„Ø¯Ø±ÙˆÙ†
        async for pos in self.drone.telemetry.position():
            lat, lon = pos.latitude_deg, pos.longitude_deg
            print(f"ğŸ“ Location Captured: {lat}, {lon}")
            
            # 2. Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù…ÙˆÙ‚Ø¹ ÙÙŠ Ø®ÙŠØ· Ù…Ù†ÙØµÙ„ (Thread) Ù„ÙƒÙŠ Ù„Ø§ ÙŠØªÙˆÙ‚Ù Ø§Ù„Ø¯Ø±ÙˆÙ†
            threading.Thread(target=upload_to_web, args=(lat, lon, image_path)).start()
            break

# -------- Ø¨Ù‚ÙŠØ© Ø§Ù„Ø¯ÙˆØ§Ù„ (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ± Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±) --------

async def wait_one_orbit(drone: System, center_lat: float, center_lon: float, radius_m: float,
                         circle_tolerance_m: float = 1.5,
                         start_tolerance_deg: float = 12 * 1e-6):
    def distance_m(lat1, lon1, lat2, lon2):
        R = 6371000
        phi1, phi2 = math.radians(lat1), math.radians(lat2)
        dphi = math.radians(lat2 - lat1)
        dlambda = math.radians(lon2 - lon1)
        a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2
        return R * 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))

    print(f"Waiting for drone to complete orbit at {radius_m}m...")
    start_lat, start_lon = 0, 0
    async for pos in drone.telemetry.position():
        if abs(distance_m(center_lat, center_lon, pos.latitude_deg, pos.longitude_deg) - radius_m) <= circle_tolerance_m:
            start_lat, start_lon = pos.latitude_deg, pos.longitude_deg
            break

    async for pos in drone.telemetry.position():
        if object_detected: return 
        if abs(pos.latitude_deg - start_lat) > start_tolerance_deg or abs(pos.longitude_deg - start_lon) > start_tolerance_deg:
            break

    async for pos in drone.telemetry.position():
        if object_detected: return
        if abs(pos.latitude_deg - start_lat) <= start_tolerance_deg and abs(pos.longitude_deg - start_lon) <= start_tolerance_deg:
            print(f"âœ… Orbit {radius_m}m completed!")
            break

async def spiral_search(drone, lat, lon, alt):
    global cv_enabled, object_detected
    print("ğŸ” Autonomous Spiral Search Started")
    cv_enabled = True 

    for radius in SPIRAL_RADII:
        if object_detected: break
        print(f"ğŸ”„ Orbiting Radius: {radius}m")
        await drone.action.do_orbit(radius_m=radius, velocity_ms=1.5, 
                                   yaw_behavior=OrbitYawBehavior.HOLD_FRONT_TO_CIRCLE_CENTER,
                                   latitude_deg=lat, longitude_deg=lon, absolute_altitude_m=alt)
        await wait_one_orbit(drone, lat, lon, radius)

async def main():
    global loop
    loop = asyncio.get_running_loop()
    rclpy.init()
    drone = System()
    await drone.connect(system_address="udp://:14540")
    
    vision_node = DroneVisionNode(drone)
    asyncio.create_task(asyncio.to_thread(rclpy.spin, vision_node))

    print("ğŸ”“ Arming and Taking off...")
    await drone.action.arm()
    await drone.action.takeoff()
    await asyncio.sleep(8)

    home = await anext(drone.telemetry.home())
    target_lat = home.latitude_deg + (11.11 * 0.000009)
    target_lon = home.longitude_deg + (15.00 * 0.000009)

    await drone.action.goto_location(target_lat, target_lon, home.absolute_altitude_m + 5, 0)
    await asyncio.sleep(10)
    await spiral_search(drone, target_lat, target_lon, home.absolute_altitude_m + 5)

    if object_detected:
        print("ğŸ  Returning to base...")
        await drone.action.return_to_launch()
    
    await asyncio.sleep(15)
    rclpy.shutdown()

if __name__ == "__main__":
    asyncio.run(main())